{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopy\n",
    "pip install geopandas\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28d5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import geodesic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f87ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S. no.</th>\n",
       "      <th>Freq</th>\n",
       "      <th>PRI</th>\n",
       "      <th>PW</th>\n",
       "      <th>Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Angle</th>\n",
       "      <th>DF_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1804</td>\n",
       "      <td>2008</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18:16:42</td>\n",
       "      <td>21.0146</td>\n",
       "      <td>25</td>\n",
       "      <td>114.643744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1805</td>\n",
       "      <td>2000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18:02:29</td>\n",
       "      <td>20.3189</td>\n",
       "      <td>25</td>\n",
       "      <td>79.535191</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1813</td>\n",
       "      <td>2001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18:32:36</td>\n",
       "      <td>21.7208</td>\n",
       "      <td>25</td>\n",
       "      <td>118.702706</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1804</td>\n",
       "      <td>2004</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18:29:14</td>\n",
       "      <td>21.6241</td>\n",
       "      <td>25</td>\n",
       "      <td>117.312487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1812</td>\n",
       "      <td>2009</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18:00:25</td>\n",
       "      <td>20.0708</td>\n",
       "      <td>25</td>\n",
       "      <td>92.877932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S. no.  Freq   PRI    PW      Time      Lat  Lon       Angle  DF_Q\n",
       "0       1  1804  2008  12.0  18:16:42  21.0146   25  114.643744     1\n",
       "1       2  1805  2000  14.0  18:02:29  20.3189   25   79.535191     7\n",
       "2       3  1813  2001  12.0  18:32:36  21.7208   25  118.702706     3\n",
       "3       4  1804  2004  11.0  18:29:14  21.6241   25  117.312487     3\n",
       "4       5  1812  2009  10.0  18:00:25  20.0708   25   92.877932     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read observation data\n",
    "obs = pd.read_excel(r\"D:\\sowrabh\\projects\\Numerical Algorithm Developer_Assignment\\Observations_001.xlsx\")\n",
    "obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194bd175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.804e+03, 2.008e+03, 1.200e+01],\n",
       "       [1.805e+03, 2.000e+03, 1.400e+01],\n",
       "       [1.813e+03, 2.001e+03, 1.200e+01],\n",
       "       ...,\n",
       "       [2.094e+03, 3.333e+03, 2.400e+00],\n",
       "       [2.092e+03, 1.666e+03, 2.400e+00],\n",
       "       [2.080e+03, 1.666e+03, 2.400e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = obs[['Freq', 'PRI', 'PW']].values\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "20ac7aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned counts per radar:\n",
      " Predicted_ID\n",
      "1.0     1000\n",
      "2.0     1000\n",
      "3.0     1000\n",
      "4.0     1000\n",
      "5.0     1000\n",
      "6.0     1000\n",
      "8.0     1000\n",
      "9.0     1000\n",
      "10.0    1000\n",
      "7.0      669\n",
      "NaN      331\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary of classified observations:\n",
      "                      Freq                            PRI                    \\\n",
      "                     mean   min   max count         mean   min   max count   \n",
      "Predicted_ID                                                                 \n",
      "1.0           1807.536000  1800  1815  1000  2005.036000  2000  2010  1000   \n",
      "2.0           1834.292000  1825  1843  1000  2589.467000  2281  3007  1000   \n",
      "3.0           1841.409000  1827  1856  1000  2753.725000  2084  3444  1000   \n",
      "4.0           1889.480000  1883  1896  1000  1022.176000   990  1054  1000   \n",
      "5.0           1923.350000  1912  1935  1000   905.890000   872   946  1000   \n",
      "6.0           1933.826000  1928  1940  1000  1941.220000  1666  2222  1000   \n",
      "7.0           1997.195815  1980  2014   669  2101.258595  2000  2200   669   \n",
      "8.0           2020.073000  2010  2030  1000  2099.000000  2099  2099  1000   \n",
      "9.0           2035.544000  2032  2039  1000  2078.387000  1642  2400  1000   \n",
      "10.0          2085.966000  2072  2100  1000  2378.484000  1666  3333  1000   \n",
      "\n",
      "                     PW                    \n",
      "                   mean   min   max count  \n",
      "Predicted_ID                               \n",
      "1.0           12.548000  10.0  15.0  1000  \n",
      "2.0            7.100900   2.6  12.7  1000  \n",
      "3.0           52.168400  10.2  98.0  1000  \n",
      "4.0           30.000000  30.0  30.0  1000  \n",
      "5.0           75.000000  75.0  75.0  1000  \n",
      "6.0            2.400000   2.4   2.4  1000  \n",
      "7.0            3.893722   1.5   6.5   669  \n",
      "8.0           10.600000  10.6  10.6  1000  \n",
      "9.0            5.442100   1.5   9.4  1000  \n",
      "10.0           2.400000   2.4   2.4  1000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df_ground_truth = pd.read_excel(\"Ground_Truth_001.xlsx\")\n",
    "df_observations = pd.read_excel(\"Observations_001.xlsx\")\n",
    "\n",
    "# --- Helper: expand ranges/lists ---\n",
    "def parse_range_or_list(value):\n",
    "    if pd.isna(value):\n",
    "        return []\n",
    "    parts = str(value).split(\",\")\n",
    "    results = []\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if \"-\" in part:\n",
    "            start, end = part.split(\"-\")\n",
    "            results.extend(np.arange(float(start), float(end) + 1))\n",
    "        else:\n",
    "            results.append(float(part))\n",
    "    return results\n",
    "\n",
    "# Expand GT params\n",
    "df_ground_truth[\"Frequency_vals\"] = df_ground_truth[\"Frequency\"].apply(parse_range_or_list)\n",
    "df_ground_truth[\"PRI_vals\"] = df_ground_truth[\"PRI\"].apply(parse_range_or_list)\n",
    "df_ground_truth[\"PW_vals\"] = df_ground_truth[\"PW\"].apply(parse_range_or_list)\n",
    "\n",
    "# --- Classification ---\n",
    "def classify_observation(freq, pri, pw, ground_truth_df):\n",
    "    for _, row in ground_truth_df.iterrows():\n",
    "        if (round(freq) in [round(v) for v in row[\"Frequency_vals\"]] and\n",
    "            round(pri) in [round(v) for v in row[\"PRI_vals\"]] and\n",
    "            round(pw) in [round(v) for v in row[\"PW_vals\"]]):\n",
    "            return row[\"Sno\"]\n",
    "    return None\n",
    "\n",
    "df_observations[\"Predicted_ID\"] = df_observations.apply(\n",
    "    lambda x: classify_observation(x[\"Freq\"], x[\"PRI\"], x[\"PW\"], df_ground_truth),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- Validation ---\n",
    "# 1. Count how many observations got assigned\n",
    "assigned_counts = df_observations[\"Predicted_ID\"].value_counts(dropna=False)\n",
    "\n",
    "# 2. Summarize observed features per radar group\n",
    "summary = df_observations.groupby(\"Predicted_ID\")[[\"Freq\", \"PRI\", \"PW\"]].agg([\"mean\", \"min\", \"max\", \"count\"])\n",
    "\n",
    "print(\"Assigned counts per radar:\\n\", assigned_counts)\n",
    "print(\"\\nSummary of classified observations:\\n\", summary)\n",
    "\n",
    "# Save results for review\n",
    "df_observations.to_excel(\"Observations_001_Classified.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7d50b612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results with Accuracy:\n",
      "   Radar_ID    Freq_obs_range     Freq_GT_range Freq_check     PRI_obs_range  \\\n",
      "0       1.0  (1800.0, 1815.0)  (1800.0, 1815.0)         OK  (2000.0, 2010.0)   \n",
      "1       2.0  (1825.0, 1843.0)  (1825.0, 1843.0)         OK  (2281.0, 3007.0)   \n",
      "2       3.0  (1827.0, 1856.0)  (1827.0, 1856.0)         OK  (2084.0, 3444.0)   \n",
      "3       4.0  (1883.0, 1896.0)  (1883.0, 1896.0)         OK   (990.0, 1054.0)   \n",
      "4       5.0  (1912.0, 1935.0)  (1912.0, 1935.0)         OK    (872.0, 946.0)   \n",
      "5       6.0  (1928.0, 1940.0)  (1928.0, 1940.0)         OK  (1666.0, 2222.0)   \n",
      "6       7.0  (1980.0, 2014.0)  (1980.0, 2014.0)         OK  (2000.0, 2200.0)   \n",
      "7       8.0  (2010.0, 2030.0)  (2010.0, 2030.0)         OK  (2099.0, 2099.0)   \n",
      "8       9.0  (2032.0, 2039.0)  (2032.0, 2039.0)         OK  (1642.0, 2400.0)   \n",
      "9      10.0  (2072.0, 2100.0)  (2072.0, 2100.0)         OK  (1666.0, 3333.0)   \n",
      "\n",
      "       PRI_GT_range PRI_check  PW_obs_range   PW_GT_range PW_check  Num_Obs  \\\n",
      "0  (2000.0, 2010.0)        OK  (10.0, 15.0)  (10.0, 15.0)       OK     1000   \n",
      "1  (2281.0, 3007.0)        OK   (2.6, 12.7)   (2.6, 12.7)       OK     1000   \n",
      "2  (2084.0, 3444.0)        OK  (10.2, 98.0)  (10.2, 98.0)       OK     1000   \n",
      "3   (990.0, 1054.0)        OK  (30.0, 30.0)  (30.0, 30.0)       OK     1000   \n",
      "4    (872.0, 946.0)        OK  (75.0, 75.0)  (75.0, 75.0)       OK     1000   \n",
      "5  (1666.0, 2222.0)        OK    (2.4, 2.4)    (2.4, 2.4)       OK     1000   \n",
      "6  (2000.0, 2200.0)        OK    (1.5, 6.5)    (1.5, 6.5)       OK      669   \n",
      "7  (2099.0, 2099.0)        OK  (10.6, 10.6)  (10.6, 10.6)       OK     1000   \n",
      "8  (1642.0, 2400.0)        OK    (1.5, 9.4)    (1.5, 9.4)       OK     1000   \n",
      "9  (1666.0, 3333.0)        OK    (2.4, 2.4)    (2.4, 2.4)       OK     1000   \n",
      "\n",
      "   Accuracy_%  \n",
      "0       100.0  \n",
      "1       100.0  \n",
      "2       100.0  \n",
      "3       100.0  \n",
      "4       100.0  \n",
      "5       100.0  \n",
      "6       100.0  \n",
      "7       100.0  \n",
      "8       100.0  \n",
      "9       100.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load data ---\n",
    "df_ground_truth = pd.read_excel(\"Ground_Truth_001.xlsx\")\n",
    "df_observations = pd.read_excel(\"Observations_001.xlsx\")\n",
    "\n",
    "# --- Helper: expand ranges/lists ---\n",
    "def parse_range_or_list(value):\n",
    "    if pd.isna(value):\n",
    "        return []\n",
    "    parts = str(value).split(\",\")\n",
    "    results = []\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if \"-\" in part:\n",
    "            start, end = part.split(\"-\")\n",
    "            results.extend(np.arange(float(start), float(end) + 1))\n",
    "        else:\n",
    "            results.append(float(part))\n",
    "    return results\n",
    "\n",
    "df_ground_truth[\"Frequency_vals\"] = df_ground_truth[\"Frequency\"].apply(parse_range_or_list)\n",
    "df_ground_truth[\"PRI_vals\"] = df_ground_truth[\"PRI\"].apply(parse_range_or_list)\n",
    "df_ground_truth[\"PW_vals\"] = df_ground_truth[\"PW\"].apply(parse_range_or_list)\n",
    "\n",
    "# --- Classification function ---\n",
    "def classify_observation(freq, pri, pw, ground_truth_df):\n",
    "    for _, row in ground_truth_df.iterrows():\n",
    "        if (round(freq) in [round(v) for v in row[\"Frequency_vals\"]] and\n",
    "            round(pri) in [round(v) for v in row[\"PRI_vals\"]] and\n",
    "            round(pw) in [round(v) for v in row[\"PW_vals\"]]):\n",
    "            return row[\"Sno\"]\n",
    "    return None\n",
    "\n",
    "df_observations[\"Predicted_ID\"] = df_observations.apply(\n",
    "    lambda x: classify_observation(x[\"Freq\"], x[\"PRI\"], x[\"PW\"], df_ground_truth),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- Summarize classified groups ---\n",
    "summary = df_observations.groupby(\"Predicted_ID\")[[\"Freq\", \"PRI\", \"PW\"]].agg([\"mean\", \"min\", \"max\", \"count\"])\n",
    "\n",
    "# --- Automated validation with accuracy scoring ---\n",
    "validation_rows = []\n",
    "for rid, stats in summary.iterrows():\n",
    "    if pd.isna(rid):\n",
    "        continue\n",
    "    gt = df_ground_truth[df_ground_truth[\"Sno\"] == rid]\n",
    "    if gt.empty:\n",
    "        continue\n",
    "    \n",
    "    # Extract GT ranges\n",
    "    freq_gt = (min(gt.iloc[0][\"Frequency_vals\"]), max(gt.iloc[0][\"Frequency_vals\"]))\n",
    "    pri_gt  = (min(gt.iloc[0][\"PRI_vals\"]), max(gt.iloc[0][\"PRI_vals\"]))\n",
    "    pw_gt   = (min(gt.iloc[0][\"PW_vals\"]), max(gt.iloc[0][\"PW_vals\"]))\n",
    "\n",
    "    # Extract observed ranges\n",
    "    freq_obs = (stats[(\"Freq\",\"min\")], stats[(\"Freq\",\"max\")])\n",
    "    pri_obs  = (stats[(\"PRI\",\"min\")], stats[(\"PRI\",\"max\")])\n",
    "    pw_obs   = (stats[(\"PW\",\"min\")], stats[(\"PW\",\"max\")])\n",
    "\n",
    "    # Checks\n",
    "    freq_flag = \"OK\" if freq_gt[0] <= freq_obs[0] and freq_gt[1] >= freq_obs[1] else \"Mismatch\"\n",
    "    pri_flag  = \"OK\" if pri_gt[0] <= pri_obs[0] and pri_gt[1] >= pri_obs[1] else \"Mismatch\"\n",
    "    pw_flag   = \"OK\" if pw_gt[0] <= pw_obs[0] and pw_gt[1] >= pw_obs[1] else \"Mismatch\"\n",
    "\n",
    "    # Accuracy score\n",
    "    checks = [freq_flag, pri_flag, pw_flag]\n",
    "    accuracy = (checks.count(\"OK\") / len(checks)) * 100\n",
    "\n",
    "    validation_rows.append({\n",
    "        \"Radar_ID\": rid,\n",
    "        \"Freq_obs_range\": freq_obs,\n",
    "        \"Freq_GT_range\": freq_gt,\n",
    "        \"Freq_check\": freq_flag,\n",
    "        \"PRI_obs_range\": pri_obs,\n",
    "        \"PRI_GT_range\": pri_gt,\n",
    "        \"PRI_check\": pri_flag,\n",
    "        \"PW_obs_range\": pw_obs,\n",
    "        \"PW_GT_range\": pw_gt,\n",
    "        \"PW_check\": pw_flag,\n",
    "        \"Num_Obs\": int(stats[(\"Freq\",\"count\")]),\n",
    "        \"Accuracy_%\": round(accuracy, 1)\n",
    "    })\n",
    "\n",
    "df_validation = pd.DataFrame(validation_rows)\n",
    "\n",
    "# --- Output ---\n",
    "print(\"Validation Results with Accuracy:\")\n",
    "print(df_validation)\n",
    "\n",
    "# Save for review\n",
    "df_validation.to_excel(\"Radar_Classification_Validation.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there were no predictive id assigned to some observations\n",
    "# This could be due to several reasons: \n",
    "# 1. The observations may not have enough information to establish a reliable association with a predictive ID.\n",
    "# 2. There could be errors or noise in the data that prevent accurate matching.\n",
    "# 3. The model may not have been trained on similar observations, leading to a lack of generalization.\n",
    "# 4. The threshold for assigning predictive IDs may be too strict, resulting in unassigned observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ba15a",
   "metadata": {},
   "source": [
    "Radar Location Estimation with Error Distances OBSERVATION 001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50daf5b3",
   "metadata": {},
   "source": [
    "TRIANGULATION ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be2926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Radar_ID    Est_Lat    Est_Lon   GT_Lat   GT_Lon  Error_km\n",
      "0       1.0  20.853506  25.788775  19.8775  27.6946    226.42\n",
      "1       2.0  21.177564  25.749438  20.4273  27.8330    232.27\n",
      "2       3.0  22.046039  25.853197  21.5086  28.1758    247.47\n",
      "3       4.0  24.369841  23.641062  24.4546  22.6310    102.87\n",
      "4       5.0  25.045230  23.444572  25.0335  21.4268    203.63\n",
      "5       6.0  25.758395  25.957726  26.1642  26.6978     86.69\n",
      "6       7.0  26.762006  24.282267  26.1381  23.6046     96.68\n",
      "7       8.0  27.717571  24.209774  27.2327  23.8347     65.28\n",
      "8       9.0  28.965532  24.094302  28.3128  22.2464    194.62\n",
      "9      10.0  29.475407  25.977803  29.4965  26.8206     81.77\n",
      "Radar Location Estimation with Error Distances:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from math import radians, degrees, sin, cos, atan2\n",
    "\n",
    "# --- Coordinate conversion helpers ---\n",
    "def geodetic_to_ecef(lat, lon):\n",
    "    \"\"\"Convert geodetic lat/lon (degrees) to ECEF coordinates (meters).\"\"\"\n",
    "    R = 6371000  # Earth radius (m)\n",
    "    lat, lon = radians(lat), radians(lon)\n",
    "    x = R * cos(lat) * cos(lon)\n",
    "    y = R * cos(lat) * sin(lon)\n",
    "    z = R * sin(lat)\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "#Bearing is the angular direction or heading from one point to another, measured clockwise from North (0°), where East is 90°, South is 180°, and West is 270°\n",
    "\n",
    "\n",
    "def bearing_to_unit_vector(lat, lon, bearing):\n",
    "    \"\"\"Convert AoA (bearing from north, degrees) into unit direction vector in ECEF.\"\"\"\n",
    "    lat, lon, bearing = map(radians, [lat, lon, bearing])\n",
    "    \n",
    "    # Local ENU (East, North, Up) basis vectors https://gssc.esa.int/navipedia/index.php/Transformations_between_ECEF_and_ENU_coordinates\n",
    "    e = np.array([-sin(lon), cos(lon), 0])\n",
    "    n = np.array([-sin(lat)*cos(lon), -sin(lat)*sin(lon), cos(lat)])\n",
    "    \n",
    "    # Direction in ENU (east-north-up)\n",
    "    dir_enu = sin(bearing) * e + cos(bearing) * n\n",
    "    \n",
    "    # Convert ENU direction to ECEF\n",
    "    return dir_enu / np.linalg.norm(dir_enu)\n",
    "\n",
    "def triangulate_location(observations):\n",
    "    \"\"\"Estimate radar location by least squares intersection of AoA lines.\"\"\"\n",
    "    A = np.zeros((3, 3))\n",
    "    b = np.zeros(3)\n",
    "    \n",
    "    for _, row in observations.iterrows():\n",
    "        p = geodetic_to_ecef(row[\"Lat\"], row[\"Lon\"])\n",
    "        d = bearing_to_unit_vector(row[\"Lat\"], row[\"Lon\"], row[\"Angle\"])\n",
    "        \n",
    "        # Projection matrix\n",
    "        I = np.eye(3)\n",
    "        P = I - np.outer(d, d)\n",
    "        \n",
    "        A += P\n",
    "        b += P @ p\n",
    "    \n",
    "    x = np.linalg.lstsq(A, b, rcond=None)[0]  # least-squares solution\n",
    "    \n",
    "    # Convert back to lat/lon\n",
    "   \n",
    "    lat = degrees(np.arcsin(x[2] / np.linalg.norm(x)))\n",
    "    lon = degrees(np.arctan2(x[1], x[0]))\n",
    "    \n",
    "    return lat, lon\n",
    "\n",
    "# --- Apply to dataset ---\n",
    "df_ground_truth = pd.read_excel(\"Ground_Truth_001.xlsx\")\n",
    "df_observations = pd.read_excel(\"Observations_001_Classified.xlsx\")\n",
    "\n",
    "if \"Predicted_ID\" not in df_observations.columns:\n",
    "    raise ValueError(\"Run Task 1 classification first to add Predicted_ID!\")\n",
    "\n",
    "estimated_locations = []\n",
    "for radar_id, group in df_observations.groupby(\"Predicted_ID\"):\n",
    "    if pd.isna(radar_id) or len(group) < 2:\n",
    "        continue\n",
    "    est_lat, est_lon = triangulate_location(group)\n",
    "    estimated_locations.append({\"Radar_ID\": radar_id, \"Est_Lat\": est_lat, \"Est_Lon\": est_lon})\n",
    "\n",
    "df_estimated = pd.DataFrame(estimated_locations)\n",
    "\n",
    "# --- Compute error distances against ground truth ---\n",
    "errors = []\n",
    "for _, row in df_estimated.iterrows():\n",
    "    gt = df_ground_truth[df_ground_truth[\"Sno\"] == row[\"Radar_ID\"]]\n",
    "    if not gt.empty:\n",
    "        gt_lat, gt_lon = gt.iloc[0][\"Latitude\"], gt.iloc[0][\"Longitude\"]\n",
    "        est_point, gt_point = (row[\"Est_Lat\"], row[\"Est_Lon\"]), (gt_lat, gt_lon)\n",
    "        error_km = geodesic(est_point, gt_point).km\n",
    "        errors.append({\n",
    "            \"Radar_ID\": row[\"Radar_ID\"],\n",
    "            \"Est_Lat\": row[\"Est_Lat\"], \n",
    "            \"Est_Lon\": row[\"Est_Lon\"],\n",
    "            \"GT_Lat\": gt_lat, \n",
    "            \"GT_Lon\": gt_lon,\n",
    "            \"Error_km\": round(error_km, 2)\n",
    "        })\n",
    "\n",
    "df_errors = pd.DataFrame(errors)\n",
    "print(df_errors)\n",
    "df_errors.to_excel(\"Radar_Location_Errors.xlsx\", index=False)\n",
    "\n",
    "# --- Compare with ground truth ---\n",
    "errors = []\n",
    "for _, row in df_estimated.iterrows():\n",
    "    gt = df_ground_truth[df_ground_truth[\"Sno\"] == row[\"Radar_ID\"]]\n",
    "    if not gt.empty:\n",
    "        gt_lat, gt_lon = gt.iloc[0][\"Latitude\"], gt.iloc[0][\"Longitude\"]\n",
    "        est_point = (row[\"Est_Lat\"], row[\"Est_Lon\"])\n",
    "        gt_point = (gt_lat, gt_lon)\n",
    "        dist_error = geodesic(est_point, gt_point).km\n",
    "        errors.append({\n",
    "            \"Radar_ID\": row[\"Radar_ID\"],\n",
    "            \"Est_Lat\": row[\"Est_Lat\"],\n",
    "            \"Est_Lon\": row[\"Est_Lon\"],\n",
    "            \"GT_Lat\": gt_lat,\n",
    "            \"GT_Lon\": gt_lon,\n",
    "            \"Error_km\": round(dist_error, 2)\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "df_errors = pd.DataFrame(errors)\n",
    "\n",
    "print(\"Radar Location Estimation with Error Distances:\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246cee23",
   "metadata": {},
   "source": [
    "TRIANGULATION ALGORITHM CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710989c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# x is the least-squares solution to the system of equations defined by the observations. It represents the estimated position of the radar in ECEF coordinates.\n",
    "#    I = np.eye(3)  P = I - np.outer(d, d) A += P b += P @ p\n",
    "# I is the 3x3 identity matrix. P is the projection matrix that projects points onto the plane perpendicular to the direction vector d. A accumulates these projection matrices, and b accumulates the projected observation points.\n",
    "#   np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "# np.linalg.lstsq(A, b, rcond=None)[0] is the least-squares solution to the linear system Ax = b. It finds the x that minimizes the Euclidean 2-norm ||Ax - b||^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "29f18e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29.47540672667637, 25.97780291975912)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangulate_location(df_observations[df_observations[\"Predicted_ID\"] == 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "48a618d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radar_ID</th>\n",
       "      <th>Est_Lat</th>\n",
       "      <th>Est_Lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.853506</td>\n",
       "      <td>25.788775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.177564</td>\n",
       "      <td>25.749438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22.046039</td>\n",
       "      <td>25.853197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>24.369841</td>\n",
       "      <td>23.641062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>25.045230</td>\n",
       "      <td>23.444572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>25.758395</td>\n",
       "      <td>25.957726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>26.762006</td>\n",
       "      <td>24.282267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>27.717571</td>\n",
       "      <td>24.209774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>28.965532</td>\n",
       "      <td>24.094302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>29.475407</td>\n",
       "      <td>25.977803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Radar_ID    Est_Lat    Est_Lon\n",
       "0       1.0  20.853506  25.788775\n",
       "1       2.0  21.177564  25.749438\n",
       "2       3.0  22.046039  25.853197\n",
       "3       4.0  24.369841  23.641062\n",
       "4       5.0  25.045230  23.444572\n",
       "5       6.0  25.758395  25.957726\n",
       "6       7.0  26.762006  24.282267\n",
       "7       8.0  27.717571  24.209774\n",
       "8       9.0  28.965532  24.094302\n",
       "9      10.0  29.475407  25.977803"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estimated = pd.DataFrame(estimated_locations)\n",
    "df_estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9d3fbee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radar_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e09dc",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf601e",
   "metadata": {},
   "source": [
    "CENTROID METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64079ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radar Location Estimation with Error Distances:\n",
      "   Radar_ID    Est_Lat  Est_Lon   GT_Lat   GT_Lon  Error_km\n",
      "0       1.0  21.021944     25.0  19.8775  27.6946    308.39\n",
      "1       2.0  21.246498     25.0  20.4273  27.8330    308.49\n",
      "2       3.0  21.997906     25.0  21.5086  28.1758    332.93\n",
      "3       4.0  23.518633     25.0  24.4546  22.6310    262.41\n",
      "4       5.0  24.523387     25.0  25.0335  21.4268    365.74\n",
      "5       6.0  24.578130     25.0  26.1642  26.6978    245.08\n",
      "6       7.0  27.006850     25.0  26.1381  23.6046    169.09\n",
      "7       8.0  27.992588     25.0  27.2327  23.8347    142.55\n",
      "8       9.0  29.031333     25.0  28.3128  22.2464    280.68\n",
      "9      10.0  28.989062     25.0  29.4965  26.8206    185.70\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from geopy.distance import geodesic\n",
    "# from math import radians, degrees, sin, cos, atan2\n",
    "\n",
    "# # --- Load data ---\n",
    "# df_ground_truth = pd.read_excel(\"Ground_Truth_001.xlsx\")\n",
    "# df_observations = pd.read_excel(\"Observations_001_Classified.xlsx\")\n",
    "\n",
    "# # --- Helper: bearing to line intersection (least squares) ---\n",
    "# def bearing_to_vector(lat, lon, bearing):\n",
    "#     \"\"\"\n",
    "#     Convert (lat, lon, bearing) into a direction vector in Cartesian coordinates.\n",
    "#     \"\"\"\n",
    "#     lat, lon, bearing = map(radians, [lat, lon, bearing])\n",
    "#     # direction vector components\n",
    "#     dx = cos(lat) * cos(lon)\n",
    "#     dy = cos(lat) * sin(lon)\n",
    "#     dz = sin(lat)\n",
    "#     # bearing vector (simplified for small areas)\n",
    "#     bx = -sin(bearing)\n",
    "#     by = cos(bearing)\n",
    "#     return np.array([dx+bx, dy+by, dz])  # direction\n",
    "\n",
    "# def estimate_radar_location(observations):\n",
    "#     \"\"\"\n",
    "#     Estimate radar location from multiple (Lat, Lon, AoA).\n",
    "#     Uses average intersection approach.\n",
    "#     \"\"\"\n",
    "#     lat_mean = np.mean(observations[\"Lat\"].values)\n",
    "#     lon_mean = np.mean(observations[\"Lon\"].values)\n",
    "#     return lat_mean, lon_mean  # fallback simple centroid if limited data\n",
    "\n",
    "# # --- Group observations by predicted radar ID (from Task 1) ---\n",
    "# if \"Predicted_ID\" not in df_observations.columns:\n",
    "#     raise ValueError(\"Run Task 1 classification first and add Predicted_ID column!\")\n",
    "\n",
    "# estimated_locations = []\n",
    "# for radar_id, group in df_observations.groupby(\"Predicted_ID\"):\n",
    "#     if pd.isna(radar_id):\n",
    "#         continue\n",
    "#     if len(group) < 2:\n",
    "#         continue\n",
    "#     est_lat, est_lon = estimate_radar_location(group)\n",
    "#     estimated_locations.append({\n",
    "#         \"Radar_ID\": radar_id,\n",
    "#         \"Est_Lat\": est_lat,\n",
    "#         \"Est_Lon\": est_lon\n",
    "#     })\n",
    "\n",
    "# df_estimated = pd.DataFrame(estimated_locations)\n",
    "\n",
    "# # --- Compare with ground truth ---\n",
    "# errors = []\n",
    "# for _, row in df_estimated.iterrows():\n",
    "#     gt = df_ground_truth[df_ground_truth[\"Sno\"] == row[\"Radar_ID\"]]\n",
    "#     if not gt.empty:\n",
    "#         gt_lat, gt_lon = gt.iloc[0][\"Latitude\"], gt.iloc[0][\"Longitude\"]\n",
    "#         est_point = (row[\"Est_Lat\"], row[\"Est_Lon\"])\n",
    "#         gt_point = (gt_lat, gt_lon)\n",
    "#         dist_error = geodesic(est_point, gt_point).km\n",
    "#         errors.append({\n",
    "#             \"Radar_ID\": row[\"Radar_ID\"],\n",
    "#             \"Est_Lat\": row[\"Est_Lat\"],\n",
    "#             \"Est_Lon\": row[\"Est_Lon\"],\n",
    "#             \"GT_Lat\": gt_lat,\n",
    "#             \"GT_Lon\": gt_lon,\n",
    "#             \"Error_km\": round(dist_error, 2)\n",
    "#         })\n",
    "\n",
    "# df_errors = pd.DataFrame(errors)\n",
    "\n",
    "# print(\"Radar Location Estimation with Error Distances:\")\n",
    "# print(df_errors)\n",
    "\n",
    "# # Save results\n",
    "# df_errors.to_excel(\"Radar_Location_Errors.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404354ea",
   "metadata": {},
   "source": [
    "REMOVED DF_Q 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f1e57760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Location Errors (before vs. after DF_Q filtering):\n",
      "   Radar_ID  Est_Lat_orig  Est_Lon_orig  GT_Lat_orig  GT_Lon_orig  Error_km  \\\n",
      "0         1     21.021944            25      19.8775      27.6946    308.39   \n",
      "1         2     21.246498            25      20.4273      27.8330    308.49   \n",
      "2         3     21.997906            25      21.5086      28.1758    332.93   \n",
      "3         4     23.518633            25      24.4546      22.6310    262.41   \n",
      "4         5     24.523387            25      25.0335      21.4268    365.74   \n",
      "5         6     24.578130            25      26.1642      26.6978    245.08   \n",
      "6         7     27.006850            25      26.1381      23.6046    169.09   \n",
      "7         8     27.992588            25      27.2327      23.8347    142.55   \n",
      "8         9     29.031333            25      28.3128      22.2464    280.68   \n",
      "9        10     28.989062            25      29.4965      26.8206    185.70   \n",
      "\n",
      "   Est_Lat_filtered  Est_Lon_filtered  GT_Lat_filtered  GT_Lon_filtered  \\\n",
      "0         19.909265         27.641715          19.8775          27.6946   \n",
      "1         20.435567         27.810091          20.4273          27.8330   \n",
      "2         21.530175         28.084484          21.5086          28.1758   \n",
      "3         24.443618         22.651614          24.4546          22.6310   \n",
      "4         25.024375         21.430336          25.0335          21.4268   \n",
      "5         26.149270         26.685627          26.1642          26.6978   \n",
      "6         26.140598         23.598511          26.1381          23.6046   \n",
      "7         27.237803         23.827969          27.2327          23.8347   \n",
      "8         28.316172         22.243420          28.3128          22.2464   \n",
      "9         29.493865         26.822089          29.4965          26.8206   \n",
      "\n",
      "   Error_km_filtered  \n",
      "0               6.56  \n",
      "1               2.56  \n",
      "2               9.76  \n",
      "3               2.42  \n",
      "4               1.07  \n",
      "5               2.05  \n",
      "6               0.67  \n",
      "7               0.87  \n",
      "8               0.47  \n",
      "9               0.33  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# --- Load again (with classifications already assigned from Task 1) ---\n",
    "df_ground_truth = pd.read_excel(\"Ground_Truth_001.xlsx\")\n",
    "df_observations = pd.read_excel(\"Observations_001_Classified.xlsx\")\n",
    "\n",
    "# Ensure Predicted_ID exists (from Task 1 classification step)\n",
    "if \"Predicted_ID\" not in df_observations.columns:\n",
    "    raise ValueError(\"Run Task 1 classification first to add Predicted_ID!\")\n",
    "\n",
    "# --- Triangulation function (from Task 2) ---\n",
    "import numpy as np\n",
    "from math import radians, degrees, sin, cos, atan2\n",
    "\n",
    "def geodetic_to_ecef(lat, lon):\n",
    "    R = 6371000\n",
    "    lat, lon = radians(lat), radians(lon)\n",
    "    x = R * cos(lat) * cos(lon)\n",
    "    y = R * cos(lat) * sin(lon)\n",
    "    z = R * sin(lat)\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def bearing_to_unit_vector(lat, lon, bearing):\n",
    "    lat, lon, bearing = map(radians, [lat, lon, bearing])\n",
    "    e = np.array([-sin(lon), cos(lon), 0])\n",
    "    n = np.array([-sin(lat)*cos(lon), -sin(lat)*sin(lon), cos(lat)])\n",
    "    dir_enu = sin(bearing) * e + cos(bearing) * n\n",
    "    return dir_enu / np.linalg.norm(dir_enu)\n",
    "\n",
    "def triangulate_location(observations):\n",
    "    A = np.zeros((3, 3))\n",
    "    b = np.zeros(3)\n",
    "    for _, row in observations.iterrows():\n",
    "        p = geodetic_to_ecef(row[\"Lat\"], row[\"Lon\"])\n",
    "        d = bearing_to_unit_vector(row[\"Lat\"], row[\"Lon\"], row[\"Angle\"])\n",
    "        P = np.eye(3) - np.outer(d, d)\n",
    "        A += P\n",
    "        b += P @ p\n",
    "    x = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "    lat = degrees(np.arcsin(x[2] / np.linalg.norm(x)))\n",
    "    lon = degrees(np.arctan2(x[1], x[0]))\n",
    "    return lat, lon\n",
    "\n",
    "# --- Step 1: Run estimation with DF_Q filter ---\n",
    "df_filtered = df_observations[df_observations[\"DF_Q\"].isin([1, 2])]\n",
    "\n",
    "filtered_locations = []\n",
    "for radar_id, group in df_filtered.groupby(\"Predicted_ID\"):\n",
    "    if pd.isna(radar_id) or len(group) < 2:\n",
    "        continue\n",
    "    est_lat, est_lon = triangulate_location(group)\n",
    "    filtered_locations.append({\n",
    "        \"Radar_ID\": radar_id,\n",
    "        \"Est_Lat\": est_lat,\n",
    "        \"Est_Lon\": est_lon\n",
    "    })\n",
    "\n",
    "df_filtered_est = pd.DataFrame(filtered_locations)\n",
    "\n",
    "# --- Step 2: Compare with ground truth ---\n",
    "filtered_errors = []\n",
    "for _, row in df_filtered_est.iterrows():\n",
    "    gt = df_ground_truth[df_ground_truth[\"Sno\"] == row[\"Radar_ID\"]]\n",
    "    if not gt.empty:\n",
    "        gt_lat, gt_lon = gt.iloc[0][\"Latitude\"], gt.iloc[0][\"Longitude\"]\n",
    "        est_point, gt_point = (row[\"Est_Lat\"], row[\"Est_Lon\"]), (gt_lat, gt_lon)\n",
    "        error_km = geodesic(est_point, gt_point).km\n",
    "        filtered_errors.append({\n",
    "            \"Radar_ID\": row[\"Radar_ID\"],\n",
    "            \"Est_Lat\": row[\"Est_Lat\"], \"Est_Lon\": row[\"Est_Lon\"],\n",
    "            \"GT_Lat\": gt_lat, \"GT_Lon\": gt_lon,\n",
    "            \"Error_km_filtered\": round(error_km, 2)\n",
    "        })\n",
    "\n",
    "df_filtered_errors = pd.DataFrame(filtered_errors)\n",
    "\n",
    "# --- Step 3: Merge with previous (unfiltered) errors for comparison ---\n",
    "df_errors = pd.read_excel(\"Radar_Location_Errors.xlsx\")  # from Task 2 output\n",
    "df_comparison = df_errors.merge(df_filtered_errors, on=\"Radar_ID\", suffixes=(\"_orig\", \"_filtered\"))\n",
    "\n",
    "print(\"Comparison of Location Errors (before vs. after DF_Q filtering):\")\n",
    "print(df_comparison)\n",
    "\n",
    "# Save\n",
    "df_comparison.to_excel(\"Radar_Location_Error_Comparison.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18374924",
   "metadata": {},
   "source": [
    "Observations_011:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c4fdc",
   "metadata": {},
   "source": [
    "Observations_011: Ground truth\n",
    "■ Number of radars identified and their parameters.\n",
    "■ Estimated radar locations (Lat/Lon). \n",
    "■ Location estimates after excluding DFQ = 1,2 observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf65efbf",
   "metadata": {},
   "source": [
    "Observations_011: Ground truth_011\n",
    "■ Number of radars identified and their parameters.\n",
    "■ Estimated radar locations (Lat/Lon). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a0e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of radars detected: 3\n",
      "   Sno_011 Freq_range  PRI_range   PW_range  Est_Lat   Est_Lon  Num_Obs\n",
      "0        1    854-899  2000-2200    1.5-1.5 -4.18435  19.86632      510\n",
      "1        2  1000-2000     10-100    0.1-2.0 -4.00074  20.06131     1307\n",
      "2        3    854-899  2000-2200  1.94-1.94 -4.17764  19.80184      490\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from math import radians, degrees, sin, cos, atan2\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# --- Load observations ---\n",
    "df_observations = pd.read_excel(\"Observations_011.xlsx\")  # repeat for 012\n",
    "\n",
    "# --- Step 1: Cluster observations by RF parameters, this will help identify distinct radars ---\n",
    "features = df_observations[[\"Freq(MHz)\", \"PRI(usec)\", \"PW(usec)\"]].values\n",
    "\n",
    "# Normalize before clustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(features)\n",
    "\n",
    "# DBSCAN: groups close RF signatures\n",
    "db = DBSCAN(eps=0.3, min_samples=20).fit(X)\n",
    "\n",
    "df_observations[\"Predicted_ID\"] = db.labels_  # -1 = noise\n",
    "\n",
    "# Remove noise (-1) and reindex clusters starting from 1\n",
    "valid_clusters = sorted([c for c in df_observations[\"Predicted_ID\"].unique() if c != -1])\n",
    "\n",
    "cluster_map = {old: new+1 for new, old in enumerate(valid_clusters)}\n",
    "\n",
    "df_observations[\"Predicted_ID\"] = df_observations[\"Predicted_ID\"].map(cluster_map)\n",
    "\n",
    "# --- Step 2: Triangulation functions (reuse from Task 2) ---\n",
    "def geodetic_to_ecef(lat, lon):\n",
    "    R = 6371000\n",
    "    lat, lon = radians(lat), radians(lon)\n",
    "    x = R * cos(lat) * cos(lon)\n",
    "    y = R * cos(lat) * sin(lon)\n",
    "    z = R * sin(lat)\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def bearing_to_unit_vector(lat, lon, bearing):\n",
    "    lat, lon, bearing = map(radians, [lat, lon, bearing])\n",
    "    e = np.array([-sin(lon), cos(lon), 0])\n",
    "    n = np.array([-sin(lat)*cos(lon), -sin(lat)*sin(lon), cos(lat)])\n",
    "    dir_enu = sin(bearing) * e + cos(bearing) * n\n",
    "    return dir_enu / np.linalg.norm(dir_enu)\n",
    "\n",
    "def triangulate_location(observations):\n",
    "    A = np.zeros((3, 3))\n",
    "    b = np.zeros(3)\n",
    "    for _, row in observations.iterrows():\n",
    "        p = geodetic_to_ecef(row[\"Lat\"], row[\"Lon\"])\n",
    "        d = bearing_to_unit_vector(row[\"Lat\"], row[\"Lon\"], row[\"Angle\"])\n",
    "        P = np.eye(3) - np.outer(d, d)\n",
    "        A += P\n",
    "        b += P @ p\n",
    "    x = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "    lat = degrees(np.arcsin(x[2] / np.linalg.norm(x)))\n",
    "    lon = degrees(np.arctan2(x[1], x[0]))\n",
    "    return lat, lon\n",
    "\n",
    "# --- Step 3: Generate Ground Truth ---\n",
    "generated_ground_truth = []\n",
    "for radar_id, group in df_observations.groupby(\"Predicted_ID\"):\n",
    "    if radar_id == -1 or len(group) < 5:  # ignore noise/small groups\n",
    "        continue\n",
    "    est_lat, est_lon = triangulate_location(group)\n",
    "    generated_ground_truth.append({\n",
    "        \"Sno_011\": radar_id,\n",
    "        \"Freq_range\": f\"{group['Freq(MHz)'].min()}-{group['Freq(MHz)'].max()}\",\n",
    "        \"PRI_range\": f\"{group['PRI(usec)'].min()}-{group['PRI(usec)'].max()}\",\n",
    "        \"PW_range\": f\"{group['PW(usec)'].min()}-{group['PW(usec)'].max()}\",\n",
    "        \"Est_Lat\": round(est_lat, 5),\n",
    "        \"Est_Lon\": round(est_lon, 5),\n",
    "        \"Num_Obs\": len(group)\n",
    "    })\n",
    "\n",
    "df_generated = pd.DataFrame(generated_ground_truth)\n",
    "# The generated_ground_truth list is populated with dictionaries, each representing a detected radar with its estimated parameters and location like 001.\n",
    "# --- Save Deliverable ---\n",
    "df_generated.to_excel(\"Ground_Truth_011_Generated.xlsx\", index=False)\n",
    "print(\"Number of radars detected:\", len(df_generated))\n",
    "print(df_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61541c",
   "metadata": {},
   "source": [
    "Observations_011:\n",
    " \n",
    "■ Location estimates after excluding DFQ = low quality observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0549ecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sno_011   Freq_range    PRI_range     PW_range  Est_Lat   Est_Lon  Num_Obs\n",
      "0        1  1000 - 2000     10 - 100    0.1 - 2.0 -4.01210  20.06419     1088\n",
      "1        2    854 - 899  2000 - 2200  1.94 - 1.94 -4.13144  19.75173      309\n",
      "2        3    854 - 899  2000 - 2200    1.5 - 1.5 -4.12404  19.83237      306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sowra\\AppData\\Local\\Temp\\ipykernel_13492\\1379532894.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.loc[:, \"Predicted_ID\"] = db.labels_  # -1 = noise\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from math import radians, degrees, sin, cos, atan2\n",
    "\n",
    "# --- Load Observations_011 ---\n",
    "df_obs = pd.read_excel(\"Observations_011.xlsx\")\n",
    "\n",
    "# --- Step 1: Filter DF_Q values ---\n",
    "df_filtered = df_obs[~df_obs[\"DF_Q\"].isin([3, 4])]\n",
    "\n",
    "# --- Step 2: Cluster by RF parameters ---\n",
    "X = df_filtered[[\"Freq(MHz)\", \"PRI(usec)\", \"PW(usec)\"]].values\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# DBSCAN clustering (tune eps/min_samples as needed)\n",
    "db = DBSCAN(eps=0.3, min_samples=20).fit(X_scaled)\n",
    "df_filtered.loc[:, \"Predicted_ID\"] = db.labels_  # -1 = noise\n",
    "# Remove noise (-1) and reindex clusters starting from 1\n",
    "valid_clusters = sorted([c for c in df_filtered[\"Predicted_ID\"].unique() if c != -1])\n",
    "\n",
    "cluster_map = {old: new+1 for new, old in enumerate(valid_clusters)}\n",
    "\n",
    "\n",
    "# When mapping cluster_map, also use .loc:\n",
    "df_filtered.loc[:, \"Predicted_ID\"] = df_filtered[\"Predicted_ID\"].map(cluster_map)\n",
    "\n",
    "# --- Triangulation helpers ---\n",
    "def geodetic_to_ecef(lat, lon):\n",
    "    R = 6371000\n",
    "    lat, lon = radians(lat), radians(lon)\n",
    "    x = R * cos(lat) * cos(lon)\n",
    "    y = R * cos(lat) * sin(lon)\n",
    "    z = R * sin(lat)\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def bearing_to_unit_vector(lat, lon, bearing):\n",
    "    lat, lon, bearing = map(radians, [lat, lon, bearing])\n",
    "    e = np.array([-sin(lon), cos(lon), 0])\n",
    "    n = np.array([-sin(lat)*cos(lon), -sin(lat)*sin(lon), cos(lat)])\n",
    "    dir_enu = sin(bearing) * e + cos(bearing) * n\n",
    "    return dir_enu / np.linalg.norm(dir_enu)\n",
    "\n",
    "def triangulate_location(observations):\n",
    "    A = np.zeros((3, 3))\n",
    "    b = np.zeros(3)\n",
    "    for _, row in observations.iterrows():\n",
    "        p = geodetic_to_ecef(row[\"Lat\"], row[\"Lon\"])\n",
    "        d = bearing_to_unit_vector(row[\"Lat\"], row[\"Lon\"], row[\"Angle\"])\n",
    "        P = np.eye(3) - np.outer(d, d)\n",
    "        A += P\n",
    "        b += P @ p\n",
    "    x = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "\n",
    "    # Convert ECEF back to geodetic coordinates\n",
    "\n",
    "    lat = degrees(np.arcsin(x[2] / np.linalg.norm(x)))\n",
    "    lon = degrees(np.arctan2(x[1], x[0]))\n",
    "    return lat, lon\n",
    "\n",
    "# --- Step 3: Estimate radar locations ---\n",
    "radar_estimates = []\n",
    "for rid, group in df_filtered.groupby(\"Predicted_ID\"):\n",
    "    if rid == -1 or len(group) < 10:  # skip noise or very small clusters\n",
    "        continue\n",
    "    est_lat, est_lon = triangulate_location(group)\n",
    "    radar_estimates.append({\n",
    "        \"Sno_011\": rid,\n",
    "        \"Freq_range\": f\"{group['Freq(MHz)'].min()} - {group['Freq(MHz)'].max()}\",\n",
    "        \"PRI_range\": f\"{group['PRI(usec)'].min()} - {group['PRI(usec)'].max()}\",\n",
    "        \"PW_range\": f\"{group['PW(usec)'].min()} - {group['PW(usec)'].max()}\",\n",
    "        \"Est_Lat\": round(est_lat, 5),\n",
    "        \"Est_Lon\": round(est_lon, 5),\n",
    "        \"Num_Obs\": len(group)\n",
    "    })\n",
    "\n",
    "df_estimates = pd.DataFrame(radar_estimates)\n",
    "\n",
    "# --- Output ---\n",
    "\n",
    "print(df_estimates)\n",
    "\n",
    "# Save results\n",
    "df_estimates.to_excel(\"Location_Estimates_011_Filtered.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd7a50",
   "metadata": {},
   "source": [
    "Compute error change:\n",
    "\n",
    "ΔLat = Est_Lat_filtered − Est_Lat_unfiltered\n",
    "\n",
    "ΔLon = Est_Lon_filtered − Est_Lon_unfiltered\n",
    "\n",
    "ΔDist = geodesic distance difference (km)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "850c8d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Radar_ID Freq_range_x  PRI_range_x   PW_range_x  Est_Lat_Unfiltered  \\\n",
      "0         0    854 - 899  2000 - 2200    1.5 - 1.5            -4.18435   \n",
      "1         1  1000 - 2000     10 - 100    0.1 - 2.0            -4.00074   \n",
      "2         2    854 - 899  2000 - 2200  1.94 - 1.94            -4.17764   \n",
      "\n",
      "   Est_Lon_Unfiltered  Num_Obs_x Freq_range_y  PRI_range_y   PW_range_y  \\\n",
      "0            19.86632        510  1000 - 2000     10 - 100    0.1 - 2.0   \n",
      "1            20.06131       1307    854 - 899  2000 - 2200  1.94 - 1.94   \n",
      "2            19.80184        490    854 - 899  2000 - 2200    1.5 - 1.5   \n",
      "\n",
      "   Est_Lat_Filtered  Est_Lon_Filtered  Num_Obs_y  Delta_Lat  Delta_Lon  \\\n",
      "0          -4.01210          20.06419       1088    0.17225    0.19787   \n",
      "1          -4.13144          19.75173        309   -0.13070   -0.30958   \n",
      "2          -4.12404          19.83237        306    0.05360    0.03053   \n",
      "\n",
      "   Delta_Dist_km  \n",
      "0      29.077840  \n",
      "1      37.290754  \n",
      "2       6.827935  \n",
      "Location Estimates for Observations_011 (excluding DF_Q=3,4):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sowra\\AppData\\Local\\Temp\\ipykernel_13492\\2495376917.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Radar_ID\"] = db.labels_\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def estimate_locations(df):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    from math import radians, degrees, sin, cos\n",
    "\n",
    "    def geodetic_to_ecef(lat, lon):\n",
    "        R = 6371000\n",
    "        lat, lon = radians(lat), radians(lon)\n",
    "        x = R * cos(lat) * cos(lon)\n",
    "        y = R * cos(lat) * sin(lon)\n",
    "        z = R * sin(lat)\n",
    "        return [x, y, z]\n",
    "\n",
    "    def bearing_to_unit_vector(lat, lon, bearing):\n",
    "        lat, lon, bearing = map(radians, [lat, lon, bearing])\n",
    "        e = [-sin(lon), cos(lon), 0]\n",
    "        n = [-sin(lat)*cos(lon), -sin(lat)*sin(lon), cos(lat)]\n",
    "        dir_enu = [sin(bearing)*e[i] + cos(bearing)*n[i] for i in range(3)]\n",
    "        norm = sum(d**2 for d in dir_enu)**0.5\n",
    "        return [d/norm for d in dir_enu]\n",
    "\n",
    "    def triangulate_location(observations):\n",
    "        import numpy as np\n",
    "        A = np.zeros((3, 3))\n",
    "        b = np.zeros(3)\n",
    "        for _, row in observations.iterrows():\n",
    "            p = geodetic_to_ecef(row[\"Lat\"], row[\"Lon\"])\n",
    "            d = bearing_to_unit_vector(row[\"Lat\"], row[\"Lon\"], row[\"Angle\"])\n",
    "            P = np.eye(3) - np.outer(d, d)\n",
    "            A += P\n",
    "            b += P @ p\n",
    "        x = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "        lat = degrees(np.arcsin(x[2] / np.linalg.norm(x)))\n",
    "        lon = degrees(np.arctan2(x[1], x[0]))\n",
    "        return lat, lon\n",
    "\n",
    "    X = df[[\"Freq(MHz)\", \"PRI(usec)\", \"PW(usec)\"]].values\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    db = DBSCAN(eps=0.3, min_samples=20).fit(X_scaled)\n",
    "    df[\"Radar_ID\"] = db.labels_\n",
    "\n",
    "    results = []\n",
    "    for rid, group in df.groupby(\"Radar_ID\"):\n",
    "        if rid == -1 or len(group) < 10:\n",
    "            continue\n",
    "        est_lat, est_lon = triangulate_location(group)\n",
    "        results.append({\n",
    "            \"Radar_ID\": rid,\n",
    "            \"Freq_range\": f\"{group['Freq(MHz)'].min()} - {group['Freq(MHz)'].max()}\",\n",
    "            \"PRI_range\": f\"{group['PRI(usec)'].min()} - {group['PRI(usec)'].max()}\",\n",
    "            \"PW_range\": f\"{group['PW(usec)'].min()} - {group['PW(usec)'].max()}\",\n",
    "            \"Est_Lat\": round(est_lat, 5),\n",
    "            \"Est_Lon\": round(est_lon, 5),\n",
    "            \"Num_Obs\": len(group)\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- Load Observations ---\n",
    "df_obs = pd.read_excel(\"Observations_011.xlsx\")\n",
    "\n",
    "# Unfiltered estimates\n",
    "unfiltered = estimate_locations(df_obs)\n",
    "unfiltered = unfiltered.rename(columns={\"Est_Lat\": \"Est_Lat_Unfiltered\", \"Est_Lon\": \"Est_Lon_Unfiltered\"})\n",
    "\n",
    "# DF_Q filtered estimates\n",
    "df_filtered = df_obs[~df_obs[\"DF_Q\"].isin([3, 4])]\n",
    "filtered = estimate_locations(df_filtered)\n",
    "filtered = filtered.rename(columns={\"Est_Lat\": \"Est_Lat_Filtered\", \"Est_Lon\": \"Est_Lon_Filtered\"})\n",
    "\n",
    "# Merge results by Radar_ID\n",
    "comparison = pd.merge(unfiltered, filtered, on=\"Radar_ID\", how=\"outer\")\n",
    "\n",
    "# Compute change in distance\n",
    "comparison[\"Delta_Lat\"] = comparison[\"Est_Lat_Filtered\"] - comparison[\"Est_Lat_Unfiltered\"]\n",
    "comparison[\"Delta_Lon\"] = comparison[\"Est_Lon_Filtered\"] - comparison[\"Est_Lon_Unfiltered\"]\n",
    "comparison[\"Delta_Dist_km\"] = comparison.apply(\n",
    "    lambda row: geodesic(\n",
    "        (row[\"Est_Lat_Unfiltered\"], row[\"Est_Lon_Unfiltered\"]),\n",
    "        (row[\"Est_Lat_Filtered\"], row[\"Est_Lon_Filtered\"])\n",
    "    ).km if pd.notnull(row[\"Est_Lat_Unfiltered\"]) and pd.notnull(row[\"Est_Lat_Filtered\"]) else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Output results\n",
    "\n",
    "comparison.to_excel(\"Location_Estimates_011_Comparison.xlsx\", index=False)\n",
    "print(comparison)\n",
    "print(\"Location Estimates for Observations_011 (excluding DF_Q=3,4):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea48e11",
   "metadata": {},
   "source": [
    "Observations_012"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8bf868",
   "metadata": {},
   "source": [
    "Observations_012: Ground truth_012\n",
    "■ Number of radars identified and their parameters.\n",
    "■ Estimated radar locations (Lat/Lon). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ef5ef5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of radars detected: 23\n",
      "    Sno_011 Freq_range  PRI_range     PW_range  Est_Lat   Est_Lon  Num_Obs\n",
      "0       1.0  1019-1100  1001-2257    2.0-820.0 -3.71769  19.77672     1571\n",
      "1       2.0  1019-1096  1004-1391   21.0-198.0 -3.70362  19.98432       57\n",
      "2       3.0  1019-1098  1809-2304  394.0-663.0 -3.80100  20.01658      102\n",
      "3       4.0  1022-1098  2684-3047  553.0-712.0 -3.70247  19.98198       46\n",
      "4       5.0  1020-1100  2918-3557   30.0-196.0 -3.73407  20.02951       92\n",
      "5       6.0  1023-1100  2862-3273  633.0-800.0 -3.67230  20.03082       50\n",
      "6       7.0  1021-1099  2260-2881    1.0-224.0 -3.73241  19.99405      110\n",
      "7       8.0  1019-1100  3359-3997  588.0-906.0 -3.78960  19.96736      142\n",
      "8       9.0  1019-1100  1861-2734  190.0-387.0 -3.78176  19.99232      138\n",
      "9      10.0  1019-1100  3094-3965  115.0-432.0 -3.82862  19.96455      177\n",
      "10     11.0  1019-1100  1545-2300  667.0-964.0 -3.74989  20.00573      153\n",
      "11     12.0  1019-1100  2868-3746  853.0-998.0 -3.80604  19.97226      113\n",
      "12     13.0  1019-1100  1027-1471  799.0-984.0 -3.71306  20.03306       65\n",
      "13     14.0  1020-1099  2325-2790  643.0-945.0 -3.68268  19.97370       96\n",
      "14     15.0  1019-1100  3507-3998  405.0-649.0 -3.61732  20.02761       70\n",
      "15     16.0  1021-1087  2012-2231  689.0-766.0 -3.93518  20.01229       23\n",
      "16     17.0  1022-1098  2311-2629  566.0-692.0 -3.72688  19.96068       30\n",
      "17     18.0  1025-1093  3360-3620  437.0-529.0 -3.71602  20.00497       28\n",
      "18     19.0  1019-1100  3611-3932    2.0-114.0 -3.70347  20.00850       40\n",
      "19     20.0  1021-1099  2331-2573  446.0-557.0 -3.77531  20.00430       28\n",
      "20     21.0  1024-1098  3081-3339  570.0-612.0 -3.84864  20.13893       18\n",
      "21     22.0  2500-4000  1600-3500     1.0-26.0 -2.23534  20.03308     7346\n",
      "22     23.0  1030-1093  2692-2898  401.0-492.0 -3.64747  20.00401       20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from math import radians, degrees, sin, cos, atan2\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# --- Load observations ---\n",
    "df_observations = pd.read_excel(\"Observations_012.xlsx\")  # repeat for 012\n",
    "\n",
    "# --- Step 1: Cluster observations by RF parameters, this will help identify distinct radars ---\n",
    "features = df_observations[[\"Freq(MHz)\", \"PRI(usec)\", \"PW(usec)\"]].values\n",
    "\n",
    "# Normalize before clustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(features)\n",
    "\n",
    "# DBSCAN: groups close RF signatures\n",
    "db = DBSCAN(eps=0.2, min_samples=20).fit(X)\n",
    "\n",
    "df_observations[\"Predicted_ID\"] = db.labels_  # -1 = noise\n",
    "\n",
    "# Remove noise (-1) and reindex clusters starting from 1\n",
    "valid_clusters = sorted([c for c in df_observations[\"Predicted_ID\"].unique() if c != -1])\n",
    "\n",
    "cluster_map = {old: new+1 for new, old in enumerate(valid_clusters)}\n",
    "\n",
    "df_observations[\"Predicted_ID\"] = df_observations[\"Predicted_ID\"].map(cluster_map)\n",
    "\n",
    "# --- Step 2: Triangulation functions (reuse from Task 2) ---\n",
    "def geodetic_to_ecef(lat, lon):\n",
    "    R = 6371000\n",
    "    lat, lon = radians(lat), radians(lon)\n",
    "    x = R * cos(lat) * cos(lon)\n",
    "    y = R * cos(lat) * sin(lon)\n",
    "    z = R * sin(lat)\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def bearing_to_unit_vector(lat, lon, bearing):\n",
    "    lat, lon, bearing = map(radians, [lat, lon, bearing])\n",
    "    e = np.array([-sin(lon), cos(lon), 0])\n",
    "    n = np.array([-sin(lat)*cos(lon), -sin(lat)*sin(lon), cos(lat)])\n",
    "    dir_enu = sin(bearing) * e + cos(bearing) * n\n",
    "    return dir_enu / np.linalg.norm(dir_enu)\n",
    "\n",
    "def triangulate_location(observations):\n",
    "    A = np.zeros((3, 3))\n",
    "    b = np.zeros(3)\n",
    "    for _, row in observations.iterrows():\n",
    "        p = geodetic_to_ecef(row[\"Lat\"], row[\"Lon\"])\n",
    "        d = bearing_to_unit_vector(row[\"Lat\"], row[\"Lon\"], row[\"Angle\"])\n",
    "        P = np.eye(3) - np.outer(d, d)\n",
    "        A += P\n",
    "        b += P @ p\n",
    "    x = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "    lat = degrees(np.arcsin(x[2] / np.linalg.norm(x)))\n",
    "    lon = degrees(np.arctan2(x[1], x[0]))\n",
    "    return lat, lon\n",
    "\n",
    "# --- Step 3: Generate Ground Truth ---\n",
    "generated_ground_truth = []\n",
    "for radar_id, group in df_observations.groupby(\"Predicted_ID\"):\n",
    "    if radar_id == -1 or len(group) < 5:  # ignore noise/small groups\n",
    "        continue\n",
    "    est_lat, est_lon = triangulate_location(group)\n",
    "    generated_ground_truth.append({\n",
    "        \"Sno_011\": radar_id,\n",
    "        \"Freq_range\": f\"{group['Freq(MHz)'].min()}-{group['Freq(MHz)'].max()}\",\n",
    "        \"PRI_range\": f\"{group['PRI(usec)'].min()}-{group['PRI(usec)'].max()}\",\n",
    "        \"PW_range\": f\"{group['PW(usec)'].min()}-{group['PW(usec)'].max()}\",\n",
    "        \"Est_Lat\": round(est_lat, 5),\n",
    "        \"Est_Lon\": round(est_lon, 5),\n",
    "        \"Num_Obs\": len(group)\n",
    "    })\n",
    "\n",
    "df_generated = pd.DataFrame(generated_ground_truth)\n",
    "# The generated_ground_truth list is populated with dictionaries, each representing a detected radar with its estimated parameters and location like 001.\n",
    "# --- Save Deliverable ---\n",
    "df_generated.to_excel(\"Ground_Truth_012_Generated.xlsx\", index=False)\n",
    "print(\"Number of radars detected:\", len(df_generated))\n",
    "print(df_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9efd0e",
   "metadata": {},
   "source": [
    "Observations_012:\n",
    " \n",
    "■ Location estimates after excluding DFQ = low quality observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5e26d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sowra\\AppData\\Local\\Temp\\ipykernel_13492\\2036823.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1. nan  1. ... 22. 22. 22.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_filtered.loc[:, \"Predicted_ID\"] = df_filtered[\"Predicted_ID\"].map(cluster_map)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno_012</th>\n",
       "      <th>Freq_range</th>\n",
       "      <th>PRI_range</th>\n",
       "      <th>PW_range</th>\n",
       "      <th>Est_Lat</th>\n",
       "      <th>Est_Lon</th>\n",
       "      <th>Num_Obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>1001 - 2257</td>\n",
       "      <td>2.0 - 820.0</td>\n",
       "      <td>-3.71769</td>\n",
       "      <td>19.77672</td>\n",
       "      <td>1571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1019 - 1096</td>\n",
       "      <td>1004 - 1391</td>\n",
       "      <td>21.0 - 198.0</td>\n",
       "      <td>-3.70362</td>\n",
       "      <td>19.98432</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1019 - 1098</td>\n",
       "      <td>1809 - 2304</td>\n",
       "      <td>394.0 - 663.0</td>\n",
       "      <td>-3.80100</td>\n",
       "      <td>20.01658</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1022 - 1098</td>\n",
       "      <td>2684 - 3047</td>\n",
       "      <td>553.0 - 712.0</td>\n",
       "      <td>-3.70247</td>\n",
       "      <td>19.98198</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1020 - 1100</td>\n",
       "      <td>2918 - 3557</td>\n",
       "      <td>30.0 - 196.0</td>\n",
       "      <td>-3.73407</td>\n",
       "      <td>20.02951</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1023 - 1100</td>\n",
       "      <td>2862 - 3273</td>\n",
       "      <td>633.0 - 800.0</td>\n",
       "      <td>-3.67230</td>\n",
       "      <td>20.03082</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1021 - 1099</td>\n",
       "      <td>2260 - 2881</td>\n",
       "      <td>1.0 - 224.0</td>\n",
       "      <td>-3.73241</td>\n",
       "      <td>19.99405</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>3359 - 3997</td>\n",
       "      <td>588.0 - 906.0</td>\n",
       "      <td>-3.78960</td>\n",
       "      <td>19.96736</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>1861 - 2734</td>\n",
       "      <td>190.0 - 387.0</td>\n",
       "      <td>-3.78176</td>\n",
       "      <td>19.99232</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>3094 - 3965</td>\n",
       "      <td>115.0 - 432.0</td>\n",
       "      <td>-3.82862</td>\n",
       "      <td>19.96455</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>1545 - 2300</td>\n",
       "      <td>667.0 - 964.0</td>\n",
       "      <td>-3.74989</td>\n",
       "      <td>20.00573</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>2868 - 3746</td>\n",
       "      <td>853.0 - 998.0</td>\n",
       "      <td>-3.80604</td>\n",
       "      <td>19.97226</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>1027 - 1471</td>\n",
       "      <td>799.0 - 984.0</td>\n",
       "      <td>-3.71306</td>\n",
       "      <td>20.03306</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1020 - 1099</td>\n",
       "      <td>2325 - 2790</td>\n",
       "      <td>643.0 - 945.0</td>\n",
       "      <td>-3.68268</td>\n",
       "      <td>19.97370</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>3507 - 3998</td>\n",
       "      <td>405.0 - 649.0</td>\n",
       "      <td>-3.61732</td>\n",
       "      <td>20.02761</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1021 - 1087</td>\n",
       "      <td>2012 - 2231</td>\n",
       "      <td>689.0 - 766.0</td>\n",
       "      <td>-3.93518</td>\n",
       "      <td>20.01229</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1022 - 1098</td>\n",
       "      <td>2311 - 2629</td>\n",
       "      <td>566.0 - 692.0</td>\n",
       "      <td>-3.72688</td>\n",
       "      <td>19.96068</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1025 - 1093</td>\n",
       "      <td>3360 - 3620</td>\n",
       "      <td>437.0 - 529.0</td>\n",
       "      <td>-3.71602</td>\n",
       "      <td>20.00497</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>3611 - 3932</td>\n",
       "      <td>2.0 - 114.0</td>\n",
       "      <td>-3.70347</td>\n",
       "      <td>20.00850</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1021 - 1099</td>\n",
       "      <td>2331 - 2573</td>\n",
       "      <td>446.0 - 557.0</td>\n",
       "      <td>-3.77531</td>\n",
       "      <td>20.00430</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1024 - 1098</td>\n",
       "      <td>3081 - 3339</td>\n",
       "      <td>570.0 - 612.0</td>\n",
       "      <td>-3.84864</td>\n",
       "      <td>20.13893</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2500 - 4000</td>\n",
       "      <td>1600 - 3500</td>\n",
       "      <td>1.0 - 26.0</td>\n",
       "      <td>-2.23534</td>\n",
       "      <td>20.03308</td>\n",
       "      <td>7346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1030 - 1093</td>\n",
       "      <td>2692 - 2898</td>\n",
       "      <td>401.0 - 492.0</td>\n",
       "      <td>-3.64747</td>\n",
       "      <td>20.00401</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sno_012   Freq_range    PRI_range       PW_range  Est_Lat   Est_Lon  \\\n",
       "0       1.0  1019 - 1100  1001 - 2257    2.0 - 820.0 -3.71769  19.77672   \n",
       "1       2.0  1019 - 1096  1004 - 1391   21.0 - 198.0 -3.70362  19.98432   \n",
       "2       3.0  1019 - 1098  1809 - 2304  394.0 - 663.0 -3.80100  20.01658   \n",
       "3       4.0  1022 - 1098  2684 - 3047  553.0 - 712.0 -3.70247  19.98198   \n",
       "4       5.0  1020 - 1100  2918 - 3557   30.0 - 196.0 -3.73407  20.02951   \n",
       "5       6.0  1023 - 1100  2862 - 3273  633.0 - 800.0 -3.67230  20.03082   \n",
       "6       7.0  1021 - 1099  2260 - 2881    1.0 - 224.0 -3.73241  19.99405   \n",
       "7       8.0  1019 - 1100  3359 - 3997  588.0 - 906.0 -3.78960  19.96736   \n",
       "8       9.0  1019 - 1100  1861 - 2734  190.0 - 387.0 -3.78176  19.99232   \n",
       "9      10.0  1019 - 1100  3094 - 3965  115.0 - 432.0 -3.82862  19.96455   \n",
       "10     11.0  1019 - 1100  1545 - 2300  667.0 - 964.0 -3.74989  20.00573   \n",
       "11     12.0  1019 - 1100  2868 - 3746  853.0 - 998.0 -3.80604  19.97226   \n",
       "12     13.0  1019 - 1100  1027 - 1471  799.0 - 984.0 -3.71306  20.03306   \n",
       "13     14.0  1020 - 1099  2325 - 2790  643.0 - 945.0 -3.68268  19.97370   \n",
       "14     15.0  1019 - 1100  3507 - 3998  405.0 - 649.0 -3.61732  20.02761   \n",
       "15     16.0  1021 - 1087  2012 - 2231  689.0 - 766.0 -3.93518  20.01229   \n",
       "16     17.0  1022 - 1098  2311 - 2629  566.0 - 692.0 -3.72688  19.96068   \n",
       "17     18.0  1025 - 1093  3360 - 3620  437.0 - 529.0 -3.71602  20.00497   \n",
       "18     19.0  1019 - 1100  3611 - 3932    2.0 - 114.0 -3.70347  20.00850   \n",
       "19     20.0  1021 - 1099  2331 - 2573  446.0 - 557.0 -3.77531  20.00430   \n",
       "20     21.0  1024 - 1098  3081 - 3339  570.0 - 612.0 -3.84864  20.13893   \n",
       "21     22.0  2500 - 4000  1600 - 3500     1.0 - 26.0 -2.23534  20.03308   \n",
       "22     23.0  1030 - 1093  2692 - 2898  401.0 - 492.0 -3.64747  20.00401   \n",
       "\n",
       "    Num_Obs  \n",
       "0      1571  \n",
       "1        57  \n",
       "2       102  \n",
       "3        46  \n",
       "4        92  \n",
       "5        50  \n",
       "6       110  \n",
       "7       142  \n",
       "8       138  \n",
       "9       177  \n",
       "10      153  \n",
       "11      113  \n",
       "12       65  \n",
       "13       96  \n",
       "14       70  \n",
       "15       23  \n",
       "16       30  \n",
       "17       28  \n",
       "18       40  \n",
       "19       28  \n",
       "20       18  \n",
       "21     7346  \n",
       "22       20  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from math import radians, degrees, sin, cos, atan2\n",
    "\n",
    "# --- Load Observations_011 ---\n",
    "df_obs = pd.read_excel(\"Observations_012.xlsx\")\n",
    "\n",
    "# --- Step 1: Filter DF_Q values ---\n",
    "df_filtered = df_obs[~df_obs[\"DF_Q\"].isin([1,2])]\n",
    "\n",
    "# --- Step 2: Cluster by RF parameters ---\n",
    "X = df_filtered[[\"Freq(MHz)\", \"PRI(usec)\", \"PW(usec)\"]].values\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# DBSCAN clustering (tune eps/min_samples as needed)\n",
    "db = DBSCAN(eps=0.2, min_samples=20).fit(X_scaled)\n",
    "df_filtered.loc[:, \"Predicted_ID\"] = db.labels_  # -1 = noise\n",
    "# Remove noise (-1) and reindex clusters starting from 1\n",
    "valid_clusters = sorted([c for c in df_filtered[\"Predicted_ID\"].unique() if c != -1])\n",
    "\n",
    "cluster_map = {old: new+1 for new, old in enumerate(valid_clusters)}\n",
    "\n",
    "\n",
    "# When mapping cluster_map, also use .loc:\n",
    "df_filtered.loc[:, \"Predicted_ID\"] = df_filtered[\"Predicted_ID\"].map(cluster_map)\n",
    "\n",
    "# --- Triangulation helpers ---\n",
    "def geodetic_to_ecef(lat, lon):\n",
    "    R = 6371000\n",
    "    lat, lon = radians(lat), radians(lon)\n",
    "    x = R * cos(lat) * cos(lon)\n",
    "    y = R * cos(lat) * sin(lon)\n",
    "    z = R * sin(lat)\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def bearing_to_unit_vector(lat, lon, bearing):\n",
    "    lat, lon, bearing = map(radians, [lat, lon, bearing])\n",
    "    e = np.array([-sin(lon), cos(lon), 0])\n",
    "    n = np.array([-sin(lat)*cos(lon), -sin(lat)*sin(lon), cos(lat)])\n",
    "    dir_enu = sin(bearing) * e + cos(bearing) * n\n",
    "    return dir_enu / np.linalg.norm(dir_enu)\n",
    "\n",
    "def triangulate_location(observations):\n",
    "    A = np.zeros((3, 3))\n",
    "    b = np.zeros(3)\n",
    "    for _, row in observations.iterrows():\n",
    "        p = geodetic_to_ecef(row[\"Lat\"], row[\"Lon\"])\n",
    "        d = bearing_to_unit_vector(row[\"Lat\"], row[\"Lon\"], row[\"Angle\"])\n",
    "        P = np.eye(3) - np.outer(d, d)\n",
    "        A += P\n",
    "        b += P @ p\n",
    "    x = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "\n",
    "    # Convert ECEF back to geodetic coordinates\n",
    "\n",
    "    lat = degrees(np.arcsin(x[2] / np.linalg.norm(x)))\n",
    "    lon = degrees(np.arctan2(x[1], x[0]))\n",
    "    return lat, lon\n",
    "\n",
    "# --- Step 3: Estimate radar locations ---\n",
    "radar_estimates = []\n",
    "for rid, group in df_filtered.groupby(\"Predicted_ID\"):\n",
    "    if rid == -1 or len(group) < 10:  # skip noise or very small clusters\n",
    "        continue\n",
    "    est_lat, est_lon = triangulate_location(group)\n",
    "    radar_estimates.append({\n",
    "        \"Sno_012\": rid,\n",
    "        \"Freq_range\": f\"{group['Freq(MHz)'].min()} - {group['Freq(MHz)'].max()}\",\n",
    "        \"PRI_range\": f\"{group['PRI(usec)'].min()} - {group['PRI(usec)'].max()}\",\n",
    "        \"PW_range\": f\"{group['PW(usec)'].min()} - {group['PW(usec)'].max()}\",\n",
    "        \"Est_Lat\": round(est_lat, 5),\n",
    "        \"Est_Lon\": round(est_lon, 5),\n",
    "        \"Num_Obs\": len(group)\n",
    "    })\n",
    "\n",
    "df_estimates = pd.DataFrame(radar_estimates)\n",
    "\n",
    "# --- Output ---\n",
    "\n",
    "\n",
    "# Save results\n",
    "df_estimates.to_excel(\"Location_Estimates_012_Filtered.xlsx\", index=False)\n",
    "\n",
    "df_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de92ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sowra\\AppData\\Local\\Temp\\ipykernel_13492\\4164097620.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Radar_ID\"] = db.labels_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Estimates for Observations_012 (excluding DF_Q= 3/4):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radar_ID</th>\n",
       "      <th>Freq_range_x</th>\n",
       "      <th>PRI_range_x</th>\n",
       "      <th>PW_range_x</th>\n",
       "      <th>Est_Lat_Unfiltered</th>\n",
       "      <th>Est_Lon_Unfiltered</th>\n",
       "      <th>Num_Obs_x</th>\n",
       "      <th>Freq_range_y</th>\n",
       "      <th>PRI_range_y</th>\n",
       "      <th>PW_range_y</th>\n",
       "      <th>Est_Lat_Filtered</th>\n",
       "      <th>Est_Lon_Filtered</th>\n",
       "      <th>Num_Obs_y</th>\n",
       "      <th>Delta_Lat</th>\n",
       "      <th>Delta_Lon</th>\n",
       "      <th>Delta_Dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>1001 - 2257</td>\n",
       "      <td>2.0 - 820.0</td>\n",
       "      <td>-3.71769</td>\n",
       "      <td>19.77672</td>\n",
       "      <td>1571.0</td>\n",
       "      <td>1019 - 1099</td>\n",
       "      <td>1875 - 2239</td>\n",
       "      <td>3.0 - 147.0</td>\n",
       "      <td>-3.65773</td>\n",
       "      <td>19.44246</td>\n",
       "      <td>831</td>\n",
       "      <td>0.05996</td>\n",
       "      <td>-0.33426</td>\n",
       "      <td>37.720414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1019 - 1096</td>\n",
       "      <td>1004 - 1391</td>\n",
       "      <td>21.0 - 198.0</td>\n",
       "      <td>-3.70362</td>\n",
       "      <td>19.98432</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1020 - 1098</td>\n",
       "      <td>1897 - 2097</td>\n",
       "      <td>394.0 - 527.0</td>\n",
       "      <td>-3.88592</td>\n",
       "      <td>20.00925</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.18230</td>\n",
       "      <td>0.02493</td>\n",
       "      <td>20.347885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1019 - 1098</td>\n",
       "      <td>1809 - 2304</td>\n",
       "      <td>394.0 - 663.0</td>\n",
       "      <td>-3.80100</td>\n",
       "      <td>20.01658</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1021 - 1095</td>\n",
       "      <td>1045 - 1312</td>\n",
       "      <td>51.0 - 173.0</td>\n",
       "      <td>-3.80751</td>\n",
       "      <td>20.04659</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.00651</td>\n",
       "      <td>0.03001</td>\n",
       "      <td>3.410231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1022 - 1098</td>\n",
       "      <td>2684 - 3047</td>\n",
       "      <td>553.0 - 712.0</td>\n",
       "      <td>-3.70247</td>\n",
       "      <td>19.98198</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1024 - 1098</td>\n",
       "      <td>2971 - 3214</td>\n",
       "      <td>666.0 - 789.0</td>\n",
       "      <td>-3.69459</td>\n",
       "      <td>19.90750</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00788</td>\n",
       "      <td>-0.07448</td>\n",
       "      <td>8.319680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1020 - 1100</td>\n",
       "      <td>2918 - 3557</td>\n",
       "      <td>30.0 - 196.0</td>\n",
       "      <td>-3.73407</td>\n",
       "      <td>20.02951</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1020 - 1097</td>\n",
       "      <td>3789 - 3985</td>\n",
       "      <td>610.0 - 753.0</td>\n",
       "      <td>-3.96385</td>\n",
       "      <td>19.92779</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.22978</td>\n",
       "      <td>-0.10172</td>\n",
       "      <td>27.807522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1023 - 1100</td>\n",
       "      <td>2862 - 3273</td>\n",
       "      <td>633.0 - 800.0</td>\n",
       "      <td>-3.67230</td>\n",
       "      <td>20.03082</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1023 - 1099</td>\n",
       "      <td>2299 - 2613</td>\n",
       "      <td>33.0 - 167.0</td>\n",
       "      <td>-3.67344</td>\n",
       "      <td>20.01009</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.00114</td>\n",
       "      <td>-0.02073</td>\n",
       "      <td>2.306392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1021 - 1099</td>\n",
       "      <td>2260 - 2881</td>\n",
       "      <td>1.0 - 224.0</td>\n",
       "      <td>-3.73241</td>\n",
       "      <td>19.99405</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1019 - 1098</td>\n",
       "      <td>1947 - 2243</td>\n",
       "      <td>514.0 - 659.0</td>\n",
       "      <td>-3.72918</td>\n",
       "      <td>19.96892</td>\n",
       "      <td>36</td>\n",
       "      <td>0.00323</td>\n",
       "      <td>-0.02513</td>\n",
       "      <td>2.814326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>3359 - 3997</td>\n",
       "      <td>588.0 - 906.0</td>\n",
       "      <td>-3.78960</td>\n",
       "      <td>19.96736</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>3029 - 3582</td>\n",
       "      <td>867.0 - 996.0</td>\n",
       "      <td>-3.77135</td>\n",
       "      <td>20.01675</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01825</td>\n",
       "      <td>0.04939</td>\n",
       "      <td>5.845582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>1861 - 2734</td>\n",
       "      <td>190.0 - 387.0</td>\n",
       "      <td>-3.78176</td>\n",
       "      <td>19.99232</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1021 - 1093</td>\n",
       "      <td>3062 - 3418</td>\n",
       "      <td>65.0 - 152.0</td>\n",
       "      <td>-3.89383</td>\n",
       "      <td>20.06563</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.11207</td>\n",
       "      <td>0.07331</td>\n",
       "      <td>14.828342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>3094 - 3965</td>\n",
       "      <td>115.0 - 432.0</td>\n",
       "      <td>-3.82862</td>\n",
       "      <td>19.96455</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1019 - 1099</td>\n",
       "      <td>3359 - 3862</td>\n",
       "      <td>671.0 - 866.0</td>\n",
       "      <td>-3.73698</td>\n",
       "      <td>19.97432</td>\n",
       "      <td>66</td>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.00977</td>\n",
       "      <td>10.191415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>1545 - 2300</td>\n",
       "      <td>667.0 - 964.0</td>\n",
       "      <td>-3.74989</td>\n",
       "      <td>20.00573</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1019 - 1099</td>\n",
       "      <td>1285 - 1932</td>\n",
       "      <td>2.0 - 121.0</td>\n",
       "      <td>-3.65941</td>\n",
       "      <td>19.96598</td>\n",
       "      <td>71</td>\n",
       "      <td>0.09048</td>\n",
       "      <td>-0.03975</td>\n",
       "      <td>10.936297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>2868 - 3746</td>\n",
       "      <td>853.0 - 998.0</td>\n",
       "      <td>-3.80604</td>\n",
       "      <td>19.97226</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1022 - 1099</td>\n",
       "      <td>1432 - 1632</td>\n",
       "      <td>422.0 - 517.0</td>\n",
       "      <td>-3.92850</td>\n",
       "      <td>20.05710</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.12246</td>\n",
       "      <td>0.08484</td>\n",
       "      <td>16.497455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>1027 - 1471</td>\n",
       "      <td>799.0 - 984.0</td>\n",
       "      <td>-3.71306</td>\n",
       "      <td>20.03306</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1020 - 1099</td>\n",
       "      <td>2374 - 2790</td>\n",
       "      <td>722.0 - 921.0</td>\n",
       "      <td>-3.63730</td>\n",
       "      <td>19.94852</td>\n",
       "      <td>58</td>\n",
       "      <td>0.07576</td>\n",
       "      <td>-0.08454</td>\n",
       "      <td>12.585158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1020 - 1099</td>\n",
       "      <td>2325 - 2790</td>\n",
       "      <td>643.0 - 945.0</td>\n",
       "      <td>-3.68268</td>\n",
       "      <td>19.97370</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>2004 - 2642</td>\n",
       "      <td>224.0 - 382.0</td>\n",
       "      <td>-3.75168</td>\n",
       "      <td>20.00474</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.06900</td>\n",
       "      <td>0.03104</td>\n",
       "      <td>8.372917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>3507 - 3998</td>\n",
       "      <td>405.0 - 649.0</td>\n",
       "      <td>-3.61732</td>\n",
       "      <td>20.02761</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1019 - 1094</td>\n",
       "      <td>1766 - 2155</td>\n",
       "      <td>845.0 - 927.0</td>\n",
       "      <td>-3.77002</td>\n",
       "      <td>19.97970</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.15270</td>\n",
       "      <td>-0.04791</td>\n",
       "      <td>17.704338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1021 - 1087</td>\n",
       "      <td>2012 - 2231</td>\n",
       "      <td>689.0 - 766.0</td>\n",
       "      <td>-3.93518</td>\n",
       "      <td>20.01229</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1021 - 1099</td>\n",
       "      <td>1003 - 1274</td>\n",
       "      <td>474.0 - 585.0</td>\n",
       "      <td>-3.88097</td>\n",
       "      <td>20.01825</td>\n",
       "      <td>31</td>\n",
       "      <td>0.05421</td>\n",
       "      <td>0.00596</td>\n",
       "      <td>6.030947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1022 - 1098</td>\n",
       "      <td>2311 - 2629</td>\n",
       "      <td>566.0 - 692.0</td>\n",
       "      <td>-3.72688</td>\n",
       "      <td>19.96068</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1030 - 1097</td>\n",
       "      <td>1309 - 1478</td>\n",
       "      <td>270.0 - 360.0</td>\n",
       "      <td>-3.63031</td>\n",
       "      <td>19.89148</td>\n",
       "      <td>20</td>\n",
       "      <td>0.09657</td>\n",
       "      <td>-0.06920</td>\n",
       "      <td>13.157917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1025 - 1093</td>\n",
       "      <td>3360 - 3620</td>\n",
       "      <td>437.0 - 529.0</td>\n",
       "      <td>-3.71602</td>\n",
       "      <td>20.00497</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1020 - 1100</td>\n",
       "      <td>1593 - 1824</td>\n",
       "      <td>697.0 - 808.0</td>\n",
       "      <td>-3.79575</td>\n",
       "      <td>20.02069</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.07973</td>\n",
       "      <td>0.01572</td>\n",
       "      <td>8.987732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>3611 - 3932</td>\n",
       "      <td>2.0 - 114.0</td>\n",
       "      <td>-3.70347</td>\n",
       "      <td>20.00850</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1019 - 1100</td>\n",
       "      <td>3611 - 3932</td>\n",
       "      <td>2.0 - 114.0</td>\n",
       "      <td>-3.69284</td>\n",
       "      <td>20.03412</td>\n",
       "      <td>33</td>\n",
       "      <td>0.01063</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>3.079288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1021 - 1099</td>\n",
       "      <td>2331 - 2573</td>\n",
       "      <td>446.0 - 557.0</td>\n",
       "      <td>-3.77531</td>\n",
       "      <td>20.00430</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1022 - 1096</td>\n",
       "      <td>1226 - 1475</td>\n",
       "      <td>542.0 - 686.0</td>\n",
       "      <td>-3.77676</td>\n",
       "      <td>19.97270</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.00145</td>\n",
       "      <td>-0.03160</td>\n",
       "      <td>3.513771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1024 - 1098</td>\n",
       "      <td>3081 - 3339</td>\n",
       "      <td>570.0 - 612.0</td>\n",
       "      <td>-3.84864</td>\n",
       "      <td>20.13893</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1025 - 1096</td>\n",
       "      <td>2628 - 2772</td>\n",
       "      <td>46.0 - 133.0</td>\n",
       "      <td>-4.17925</td>\n",
       "      <td>20.00454</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.33061</td>\n",
       "      <td>-0.13439</td>\n",
       "      <td>39.487484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2500 - 4000</td>\n",
       "      <td>1600 - 3500</td>\n",
       "      <td>1.0 - 26.0</td>\n",
       "      <td>-2.23534</td>\n",
       "      <td>20.03308</td>\n",
       "      <td>7346.0</td>\n",
       "      <td>1019 - 1098</td>\n",
       "      <td>1131 - 1346</td>\n",
       "      <td>820.0 - 900.0</td>\n",
       "      <td>-3.78897</td>\n",
       "      <td>20.04298</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.55363</td>\n",
       "      <td>0.00990</td>\n",
       "      <td>171.799906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1030 - 1093</td>\n",
       "      <td>2692 - 2898</td>\n",
       "      <td>401.0 - 492.0</td>\n",
       "      <td>-3.64747</td>\n",
       "      <td>20.00401</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1023 - 1097</td>\n",
       "      <td>1026 - 1215</td>\n",
       "      <td>258.0 - 343.0</td>\n",
       "      <td>-3.64898</td>\n",
       "      <td>20.15987</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.00151</td>\n",
       "      <td>0.15586</td>\n",
       "      <td>17.316136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020 - 1100</td>\n",
       "      <td>3656 - 3864</td>\n",
       "      <td>320.0 - 418.0</td>\n",
       "      <td>-3.96879</td>\n",
       "      <td>20.06157</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500 - 4000</td>\n",
       "      <td>1600 - 3500</td>\n",
       "      <td>1.0 - 26.0</td>\n",
       "      <td>-2.23227</td>\n",
       "      <td>20.03170</td>\n",
       "      <td>5880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023 - 1098</td>\n",
       "      <td>3440 - 3647</td>\n",
       "      <td>234.0 - 314.0</td>\n",
       "      <td>-3.66370</td>\n",
       "      <td>19.88595</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020 - 1097</td>\n",
       "      <td>1165 - 1369</td>\n",
       "      <td>703.0 - 777.0</td>\n",
       "      <td>-3.71432</td>\n",
       "      <td>20.09362</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Radar_ID Freq_range_x  PRI_range_x     PW_range_x  Est_Lat_Unfiltered  \\\n",
       "0          0  1019 - 1100  1001 - 2257    2.0 - 820.0            -3.71769   \n",
       "1          1  1019 - 1096  1004 - 1391   21.0 - 198.0            -3.70362   \n",
       "2          2  1019 - 1098  1809 - 2304  394.0 - 663.0            -3.80100   \n",
       "3          3  1022 - 1098  2684 - 3047  553.0 - 712.0            -3.70247   \n",
       "4          4  1020 - 1100  2918 - 3557   30.0 - 196.0            -3.73407   \n",
       "5          5  1023 - 1100  2862 - 3273  633.0 - 800.0            -3.67230   \n",
       "6          6  1021 - 1099  2260 - 2881    1.0 - 224.0            -3.73241   \n",
       "7          7  1019 - 1100  3359 - 3997  588.0 - 906.0            -3.78960   \n",
       "8          8  1019 - 1100  1861 - 2734  190.0 - 387.0            -3.78176   \n",
       "9          9  1019 - 1100  3094 - 3965  115.0 - 432.0            -3.82862   \n",
       "10        10  1019 - 1100  1545 - 2300  667.0 - 964.0            -3.74989   \n",
       "11        11  1019 - 1100  2868 - 3746  853.0 - 998.0            -3.80604   \n",
       "12        12  1019 - 1100  1027 - 1471  799.0 - 984.0            -3.71306   \n",
       "13        13  1020 - 1099  2325 - 2790  643.0 - 945.0            -3.68268   \n",
       "14        14  1019 - 1100  3507 - 3998  405.0 - 649.0            -3.61732   \n",
       "15        15  1021 - 1087  2012 - 2231  689.0 - 766.0            -3.93518   \n",
       "16        16  1022 - 1098  2311 - 2629  566.0 - 692.0            -3.72688   \n",
       "17        17  1025 - 1093  3360 - 3620  437.0 - 529.0            -3.71602   \n",
       "18        18  1019 - 1100  3611 - 3932    2.0 - 114.0            -3.70347   \n",
       "19        19  1021 - 1099  2331 - 2573  446.0 - 557.0            -3.77531   \n",
       "20        20  1024 - 1098  3081 - 3339  570.0 - 612.0            -3.84864   \n",
       "21        21  2500 - 4000  1600 - 3500     1.0 - 26.0            -2.23534   \n",
       "22        22  1030 - 1093  2692 - 2898  401.0 - 492.0            -3.64747   \n",
       "23        23          NaN          NaN            NaN                 NaN   \n",
       "24        24          NaN          NaN            NaN                 NaN   \n",
       "25        25          NaN          NaN            NaN                 NaN   \n",
       "26        26          NaN          NaN            NaN                 NaN   \n",
       "\n",
       "    Est_Lon_Unfiltered  Num_Obs_x Freq_range_y  PRI_range_y     PW_range_y  \\\n",
       "0             19.77672     1571.0  1019 - 1099  1875 - 2239    3.0 - 147.0   \n",
       "1             19.98432       57.0  1020 - 1098  1897 - 2097  394.0 - 527.0   \n",
       "2             20.01658      102.0  1021 - 1095  1045 - 1312   51.0 - 173.0   \n",
       "3             19.98198       46.0  1024 - 1098  2971 - 3214  666.0 - 789.0   \n",
       "4             20.02951       92.0  1020 - 1097  3789 - 3985  610.0 - 753.0   \n",
       "5             20.03082       50.0  1023 - 1099  2299 - 2613   33.0 - 167.0   \n",
       "6             19.99405      110.0  1019 - 1098  1947 - 2243  514.0 - 659.0   \n",
       "7             19.96736      142.0  1019 - 1100  3029 - 3582  867.0 - 996.0   \n",
       "8             19.99232      138.0  1021 - 1093  3062 - 3418   65.0 - 152.0   \n",
       "9             19.96455      177.0  1019 - 1099  3359 - 3862  671.0 - 866.0   \n",
       "10            20.00573      153.0  1019 - 1099  1285 - 1932    2.0 - 121.0   \n",
       "11            19.97226      113.0  1022 - 1099  1432 - 1632  422.0 - 517.0   \n",
       "12            20.03306       65.0  1020 - 1099  2374 - 2790  722.0 - 921.0   \n",
       "13            19.97370       96.0  1019 - 1100  2004 - 2642  224.0 - 382.0   \n",
       "14            20.02761       70.0  1019 - 1094  1766 - 2155  845.0 - 927.0   \n",
       "15            20.01229       23.0  1021 - 1099  1003 - 1274  474.0 - 585.0   \n",
       "16            19.96068       30.0  1030 - 1097  1309 - 1478  270.0 - 360.0   \n",
       "17            20.00497       28.0  1020 - 1100  1593 - 1824  697.0 - 808.0   \n",
       "18            20.00850       40.0  1019 - 1100  3611 - 3932    2.0 - 114.0   \n",
       "19            20.00430       28.0  1022 - 1096  1226 - 1475  542.0 - 686.0   \n",
       "20            20.13893       18.0  1025 - 1096  2628 - 2772   46.0 - 133.0   \n",
       "21            20.03308     7346.0  1019 - 1098  1131 - 1346  820.0 - 900.0   \n",
       "22            20.00401       20.0  1023 - 1097  1026 - 1215  258.0 - 343.0   \n",
       "23                 NaN        NaN  1020 - 1100  3656 - 3864  320.0 - 418.0   \n",
       "24                 NaN        NaN  2500 - 4000  1600 - 3500     1.0 - 26.0   \n",
       "25                 NaN        NaN  1023 - 1098  3440 - 3647  234.0 - 314.0   \n",
       "26                 NaN        NaN  1020 - 1097  1165 - 1369  703.0 - 777.0   \n",
       "\n",
       "    Est_Lat_Filtered  Est_Lon_Filtered  Num_Obs_y  Delta_Lat  Delta_Lon  \\\n",
       "0           -3.65773          19.44246        831    0.05996   -0.33426   \n",
       "1           -3.88592          20.00925         32   -0.18230    0.02493   \n",
       "2           -3.80751          20.04659         34   -0.00651    0.03001   \n",
       "3           -3.69459          19.90750         28    0.00788   -0.07448   \n",
       "4           -3.96385          19.92779         33   -0.22978   -0.10172   \n",
       "5           -3.67344          20.01009         37   -0.00114   -0.02073   \n",
       "6           -3.72918          19.96892         36    0.00323   -0.02513   \n",
       "7           -3.77135          20.01675         64    0.01825    0.04939   \n",
       "8           -3.89383          20.06563         31   -0.11207    0.07331   \n",
       "9           -3.73698          19.97432         66    0.09164    0.00977   \n",
       "10          -3.65941          19.96598         71    0.09048   -0.03975   \n",
       "11          -3.92850          20.05710         25   -0.12246    0.08484   \n",
       "12          -3.63730          19.94852         58    0.07576   -0.08454   \n",
       "13          -3.75168          20.00474         75   -0.06900    0.03104   \n",
       "14          -3.77002          19.97970         36   -0.15270   -0.04791   \n",
       "15          -3.88097          20.01825         31    0.05421    0.00596   \n",
       "16          -3.63031          19.89148         20    0.09657   -0.06920   \n",
       "17          -3.79575          20.02069         27   -0.07973    0.01572   \n",
       "18          -3.69284          20.03412         33    0.01063    0.02562   \n",
       "19          -3.77676          19.97270         32   -0.00145   -0.03160   \n",
       "20          -4.17925          20.00454         16   -0.33061   -0.13439   \n",
       "21          -3.78897          20.04298         21   -1.55363    0.00990   \n",
       "22          -3.64898          20.15987         20   -0.00151    0.15586   \n",
       "23          -3.96879          20.06157         23        NaN        NaN   \n",
       "24          -2.23227          20.03170       5880        NaN        NaN   \n",
       "25          -3.66370          19.88595         20        NaN        NaN   \n",
       "26          -3.71432          20.09362         21        NaN        NaN   \n",
       "\n",
       "    Delta_Dist_km  \n",
       "0       37.720414  \n",
       "1       20.347885  \n",
       "2        3.410231  \n",
       "3        8.319680  \n",
       "4       27.807522  \n",
       "5        2.306392  \n",
       "6        2.814326  \n",
       "7        5.845582  \n",
       "8       14.828342  \n",
       "9       10.191415  \n",
       "10      10.936297  \n",
       "11      16.497455  \n",
       "12      12.585158  \n",
       "13       8.372917  \n",
       "14      17.704338  \n",
       "15       6.030947  \n",
       "16      13.157917  \n",
       "17       8.987732  \n",
       "18       3.079288  \n",
       "19       3.513771  \n",
       "20      39.487484  \n",
       "21     171.799906  \n",
       "22      17.316136  \n",
       "23            NaN  \n",
       "24            NaN  \n",
       "25            NaN  \n",
       "26            NaN  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def estimate_locations(df):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    from math import radians, degrees, sin, cos\n",
    "\n",
    "    def geodetic_to_ecef(lat, lon):\n",
    "        R = 6371000\n",
    "        lat, lon = radians(lat), radians(lon)\n",
    "        x = R * cos(lat) * cos(lon)\n",
    "        y = R * cos(lat) * sin(lon)\n",
    "        z = R * sin(lat)\n",
    "        return [x, y, z]\n",
    "\n",
    "    def bearing_to_unit_vector(lat, lon, bearing):\n",
    "        lat, lon, bearing = map(radians, [lat, lon, bearing])\n",
    "        e = [-sin(lon), cos(lon), 0]\n",
    "        n = [-sin(lat)*cos(lon), -sin(lat)*sin(lon), cos(lat)]\n",
    "        dir_enu = [sin(bearing)*e[i] + cos(bearing)*n[i] for i in range(3)]\n",
    "        norm = sum(d**2 for d in dir_enu)**0.5\n",
    "        return [d/norm for d in dir_enu]\n",
    "\n",
    "    def triangulate_location(observations):\n",
    "        import numpy as np\n",
    "        A = np.zeros((3, 3))\n",
    "        b = np.zeros(3)\n",
    "        for _, row in observations.iterrows():\n",
    "            p = geodetic_to_ecef(row[\"Lat\"], row[\"Lon\"])\n",
    "            d = bearing_to_unit_vector(row[\"Lat\"], row[\"Lon\"], row[\"Angle\"])\n",
    "            P = np.eye(3) - np.outer(d, d)\n",
    "            A += P\n",
    "            b += P @ p\n",
    "        x = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "        \n",
    "        lat = degrees(np.arcsin(x[2] / np.linalg.norm(x)))\n",
    "        lon = degrees(np.arctan2(x[1], x[0]))\n",
    "        return lat, lon\n",
    "\n",
    "    X = df[[\"Freq(MHz)\", \"PRI(usec)\", \"PW(usec)\"]].values\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    db = DBSCAN(eps=0.2, min_samples=20).fit(X_scaled)\n",
    "    df[\"Radar_ID\"] = db.labels_\n",
    "\n",
    "    results = []\n",
    "    for rid, group in df.groupby(\"Radar_ID\"):\n",
    "        if rid == -1 or len(group) < 10:\n",
    "            continue\n",
    "        est_lat, est_lon = triangulate_location(group)\n",
    "        results.append({\n",
    "            \"Radar_ID\": rid,\n",
    "            \"Freq_range\": f\"{group['Freq(MHz)'].min()} - {group['Freq(MHz)'].max()}\",\n",
    "            \"PRI_range\": f\"{group['PRI(usec)'].min()} - {group['PRI(usec)'].max()}\",\n",
    "            \"PW_range\": f\"{group['PW(usec)'].min()} - {group['PW(usec)'].max()}\",\n",
    "            \"Est_Lat\": round(est_lat, 5),\n",
    "            \"Est_Lon\": round(est_lon, 5),\n",
    "            \"Num_Obs\": len(group)\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- Load Observations ---\n",
    "df_obs = pd.read_excel(\"Observations_012.xlsx\")\n",
    "\n",
    "# Unfiltered estimates\n",
    "unfiltered = estimate_locations(df_obs)\n",
    "unfiltered = unfiltered.rename(columns={\"Est_Lat\": \"Est_Lat_Unfiltered\", \"Est_Lon\": \"Est_Lon_Unfiltered\"})\n",
    "\n",
    "# DF_Q filtered estimates\n",
    "df_filtered = df_obs[~df_obs[\"DF_Q\"].isin([3])]\n",
    "filtered = estimate_locations(df_filtered)\n",
    "filtered = filtered.rename(columns={\"Est_Lat\": \"Est_Lat_Filtered\", \"Est_Lon\": \"Est_Lon_Filtered\"})\n",
    "\n",
    "# Merge results by Radar_ID\n",
    "comparison = pd.merge(unfiltered, filtered, on=\"Radar_ID\", how=\"outer\")\n",
    "\n",
    "# Compute change in distance\n",
    "comparison[\"Delta_Lat\"] = comparison[\"Est_Lat_Filtered\"] - comparison[\"Est_Lat_Unfiltered\"]\n",
    "comparison[\"Delta_Lon\"] = comparison[\"Est_Lon_Filtered\"] - comparison[\"Est_Lon_Unfiltered\"]\n",
    "comparison[\"Delta_Dist_km\"] = comparison.apply(\n",
    "    lambda row: geodesic(\n",
    "        (row[\"Est_Lat_Unfiltered\"], row[\"Est_Lon_Unfiltered\"]),\n",
    "        (row[\"Est_Lat_Filtered\"], row[\"Est_Lon_Filtered\"])\n",
    "    ).km if pd.notnull(row[\"Est_Lat_Unfiltered\"]) and pd.notnull(row[\"Est_Lat_Filtered\"]) else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Output results\n",
    "\n",
    "comparison.to_excel(\"Location_Estimates_012_Comparison.xlsx\", index=False)\n",
    "\n",
    "print(\"Location Estimates for Observations_012 (excluding DF_Q= 3/4):\")\n",
    "comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
